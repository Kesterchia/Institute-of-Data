{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5OpoOWK6sGSo"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1CwwlV59sGSr"
   },
   "source": [
    "# Lab 8.3: Stacking\n",
    "\n",
    "INSTRUCTIONS:\n",
    "\n",
    "- Read the guides and hints then create the necessary analysis and code to find an answer and conclusion for the scenario below.\n",
    "- The baseline results (minimum) are:\n",
    "    - **Accuracy** = 0.9667\n",
    "    - **ROC AUC**  = 0.9614\n",
    "- Try to achieve better results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BbBuCjV8sGSw"
   },
   "source": [
    "## Scenario: Predicting Breast Cancer\n",
    "The dataset you are going to be using for this laboratory is popularly known as the **Wisconsin Breast Cancer** dataset. The task related to it is Classification.\n",
    "\n",
    "The dataset contains a total number of _10_ features labelled in either **benign** or **malignant** classes. The features have _699_ instances out of which _16_ feature values are missing. The dataset only contains numeric values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TDlYwu8FsGSz"
   },
   "source": [
    "# Step 1: Define the problem or question\n",
    "Identify the subject matter and the given or obvious questions that would be relevant in the field.\n",
    "\n",
    "## Potential Questions\n",
    "List the given or obvious questions.\n",
    "\n",
    "## Actual Question\n",
    "Choose the **one** question that should be answered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e7tXdNdvsGS1"
   },
   "source": [
    "# Step 2: Find the Data\n",
    "## Wisconsin Breast Cancer DataSet\n",
    "- **Citation Request**\n",
    "\n",
    "    This breast cancer databases was obtained from the **University of Wisconsin Hospitals**, **Madison** from **Dr. William H. Wolberg**. If you publish results when using this database, then please include this information in your acknowledgements.\n",
    "\n",
    "- **Title**\n",
    "\n",
    "    Wisconsin Breast Cancer Database (January 8, 1991)\n",
    "\n",
    "- **Sources**\n",
    "    - **Creator**\n",
    "            Dr. WIlliam H. Wolberg (physician)\n",
    "            University of Wisconsin Hospitals\n",
    "            Madison, Wisconsin\n",
    "            USA\n",
    "    - **Donor**\n",
    "            Olvi Mangasarian (mangasarian@cs.wisc.edu)\n",
    "            Received by David W. Aha (aha@cs.jhu.edu)\n",
    "    - **Date**\n",
    "            15 July 1992"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zk_JJ8xlsGS3"
   },
   "source": [
    "# Step 3: Read the Data\n",
    "- Read the data\n",
    "- Perform some basic structural cleaning to facilitate the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "            'Index',\n",
    "            'Clump Thickness',\n",
    "            'Uniformity of Cell Size',\n",
    "            'Uniformity of Cell Shape',\n",
    "            'Marginal Adhesion',\n",
    "            'Single Epithelial Cell Size',\n",
    "            'Bare Nuclei',\n",
    "            'Bland Chromatin',\n",
    "            'Normal Nucleoli',\n",
    "            'Mitoses',\n",
    "            'Class']\n",
    "\n",
    "df = pd.read_csv('../Data/breast-cancer-wisconsin-data-old.csv',\n",
    "                 header = None,\n",
    "                 names = columns,\n",
    "                 usecols = columns[1:], #Use all cols but first one\n",
    "                 na_values = '?' #Replace '?' with nan\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YTCAHTgLsGS5"
   },
   "source": [
    "# Step 4: Explore and Clean the Data\n",
    "- Perform some initial simple **EDA** (Exploratory Data Analysis)\n",
    "- Check for\n",
    "    - **Number of features**\n",
    "    - **Data types**\n",
    "    - **Domains, Intervals**\n",
    "    - **Outliers** (are they valid or expurious data [read or measure errors])\n",
    "    - **Null** (values not present or coded [as zero of empty strings])\n",
    "    - **Missing Values** (coded [as zero of empty strings] or values not present)\n",
    "    - **Coded content** (classes identified by numbers or codes to represent absence of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
       "0                5                        1                         1   \n",
       "1                5                        4                         4   \n",
       "2                3                        1                         1   \n",
       "3                6                        8                         8   \n",
       "4                4                        1                         1   \n",
       "\n",
       "   Marginal Adhesion  Single Epithelial Cell Size  Bare Nuclei  \\\n",
       "0                  1                            2          1.0   \n",
       "1                  5                            7         10.0   \n",
       "2                  1                            2          2.0   \n",
       "3                  1                            3          4.0   \n",
       "4                  3                            2          1.0   \n",
       "\n",
       "   Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
       "0                3                1        1      2  \n",
       "1                3                2        1      2  \n",
       "2                3                1        1      2  \n",
       "3                3                7        1      2  \n",
       "4                3                1        1      2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6nU7e3BGsGS7"
   },
   "source": [
    "# Step 5: Prepare the Data\n",
    "- Deal with the data as required by the modelling technique\n",
    "    - **Outliers** (remove or adjust if possible or necessary)\n",
    "    - **Null** (remove or interpolate if possible or necessary)\n",
    "    - **Missing Values** (remove or interpolate if possible or necessary)\n",
    "    - **Coded content** (transform if possible or necessary [str to number or vice-versa])\n",
    "    - **Normalisation** (if possible or necessary)\n",
    "    - **Feature Engeneer** (if useful or necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 10 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Clump Thickness              699 non-null    int64  \n",
      " 1   Uniformity of Cell Size      699 non-null    int64  \n",
      " 2   Uniformity of Cell Shape     699 non-null    int64  \n",
      " 3   Marginal Adhesion            699 non-null    int64  \n",
      " 4   Single Epithelial Cell Size  699 non-null    int64  \n",
      " 5   Bare Nuclei                  683 non-null    float64\n",
      " 6   Bland Chromatin              699 non-null    int64  \n",
      " 7   Normal Nucleoli              699 non-null    int64  \n",
      " 8   Mitoses                      699 non-null    int64  \n",
      " 9   Class                        699 non-null    int64  \n",
      "dtypes: float64(1), int64(9)\n",
      "memory usage: 54.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute nan values:\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "#This iterative imputer bases y on all other columns in dataframe iteratively\n",
    "\n",
    "imputer = IterativeImputer()\n",
    "\n",
    "df.loc[:,'Bare Nuclei'] = imputer.fit_transform(df[['Bare Nuclei']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize data:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Split data:\n",
    "\n",
    "X = df.drop('Class', axis = 1)\n",
    "y = df['Class']\n",
    "\n",
    "#Normalize (Scale) data:\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_X = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)\n",
    "            \n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iHsn1Y_BsGS8"
   },
   "source": [
    "# Step 6: Modelling\n",
    "Refer to the Problem and Main Question.\n",
    "- What are the input variables (features)?\n",
    "- Is there an output variable (label)?\n",
    "- If there is an output variable:\n",
    "    - What is it?\n",
    "    - What is its type?\n",
    "- What type of Modelling is it?\n",
    "    - [ ] Supervised\n",
    "    - [ ] Unsupervised \n",
    "- What type of Modelling is it?\n",
    "    - [ ] Regression\n",
    "    - [ ] Classification (binary) \n",
    "    - [ ] Classification (multi-class)\n",
    "    - [ ] Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will use a few different models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VNE4KKxrsGS-"
   },
   "source": [
    "# Step 7: Split the Data\n",
    "\n",
    "Need to check for **Supervised** modelling:\n",
    "- Number of known cases or observations\n",
    "- Define the split in Training/Test or Training/Validation/Test and their proportions\n",
    "- Check for unbalanced classes and how to keep or avoid it when spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Already done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wAdSJL2IsGS_"
   },
   "source": [
    "# Step 8: Define and Fit Models\n",
    "\n",
    "Define the model and its hyper-parameters.\n",
    "\n",
    "Consider the parameters and hyper-parameters of each model at each (re)run and after checking the efficiency of a model against the training and test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying a stacking classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import classifier:\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "\n",
    "#Import base models:\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Initialize stacked model:\n",
    "\n",
    "stack = StackingClassifier(estimators = [('Log Regressor',LogisticRegression()),\n",
    "                                         ('K-Nearest Neighbors',KNeighborsClassifier()),\n",
    "                                         ('Support vector machine',SVC()),\n",
    "                                         ('Decision Tree',DecisionTreeClassifier()),\n",
    "                                        ],\n",
    "                           final_estimator = None, #Default is Log Regression\n",
    "                           cv = None, #Default is 5-fold cv \n",
    "                           stack_method = 'auto' #Method for base models, default is predict_proba followed by a few other options\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train stacked model:\n",
    "\n",
    "stack.fit(X_train,y_train)\n",
    "\n",
    "#Generate predictions:\n",
    "\n",
    "stack_predictions = stack.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "arfz_kGXsGTA"
   },
   "source": [
    "# Step 9: Verify and Evaluate the Training Model\n",
    "- Use the **training** data to make predictions\n",
    "- Check for overfitting\n",
    "- What metrics are appropriate for the modelling approach used\n",
    "- For **Supervised** models:\n",
    "    - Check the **Training Results** with the **Training Predictions** during development\n",
    "- Analyse, modify the parameters and hyper-parameters and repeat (within reason) until the model does not improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, plot_confusion_matrix, classification_report, plot_roc_curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy for stacked model: 0.9700854700854701\n",
      "Testing accuracy for stacked model: 0.9653679653679653\n"
     ]
    }
   ],
   "source": [
    "print('Training accuracy for stacked model:', stack.score(X_train,y_train))\n",
    "print('Testing accuracy for stacked model:', accuracy_score(y_test,stack_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0V738ZOusGTB"
   },
   "source": [
    "# Step 10: Make Predictions and Evaluate the Test Model\n",
    "**NOTE**: **Do this only after not making any more improvements in the model**.\n",
    "\n",
    "- Use the **test** data to make predictions\n",
    "- For **Supervised** models:\n",
    "    - Check the **Test Results** with the **Test Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try some other regressors but with default settings:\n",
    "logmodel = LogisticRegression().fit(X_train,y_train)\n",
    "log_predictions = LogisticRegression().fit(X_train,y_train).predict(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier().fit(X_train,y_train)\n",
    "knn_predictions = knn.predict(X_test)\n",
    "\n",
    "svc = SVC().fit(X_train,y_train)\n",
    "svc_predictions = svc.predict(X_test)\n",
    "\n",
    "tree = DecisionTreeClassifier().fit(X_train,y_train)\n",
    "tree_predictions = tree.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize some lists to produce a nice dataframe:\n",
    "\n",
    "estimators_ = [stack,logmodel,knn,svc,tree]\n",
    "Estimators = ['Stacked Classifier','Logistic Regression','K-Nearest neighbors','Support Vector Machine', 'Decision Tree']\n",
    "\n",
    "#Get training scores for each model:\n",
    "training_scores = [model.score(X_train,y_train) for model in estimators_]\n",
    "\n",
    "#Get testing scores for each model:\n",
    "test_scores = [accuracy_score(y_test,model.predict(X_test)) for model in estimators_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimator</th>\n",
       "      <th>Training scores</th>\n",
       "      <th>Test scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stacked Classifier</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K-Nearest neighbors</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.961039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Estimator  Training scores  Test scores\n",
       "0      Stacked Classifier         0.970085     0.965368\n",
       "1     Logistic Regression         0.970085     0.965368\n",
       "2     K-Nearest neighbors         0.970085     0.961039\n",
       "3  Support Vector Machine         0.970085     0.969697\n",
       "4           Decision Tree         1.000000     0.943723"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data = {'Estimator': Estimators,\n",
    "                         'Training scores' : training_scores,\n",
    "                         'Test scores' : test_scores\n",
    "                        }\n",
    "                )\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "az-R88PhsGTC"
   },
   "source": [
    "# Step 11: Solve the Problem or Answer the Question\n",
    "The results of an analysis or modelling can be used:\n",
    "- As part of a product or process, so the model can make predictions when new input data is available\n",
    "- As part of a report including text and charts to help understand the problem\n",
    "- As input for further questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RERADKgNFq9T"
   },
   "source": [
    "Â© 2020 Institute of Data"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DSIA Lab-8_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
