{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fix0Ry0j1qn5"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U7WTDbVT1qn9"
   },
   "source": [
    "# Lab 10.2: CNN with Keras\n",
    "INSTRUCTIONS:\n",
    "- Read the guides and hints, then create the necessary analysis and code to find an answer and conclusion for the task below.\n",
    "- A guide you are encouraged to read through is TensorFlow's own tutorial for image classification, which can be found [here](https://www.tensorflow.org/tutorials/images/cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EWGurboj1qoA"
   },
   "source": [
    "# CIFAR10 small image classification\n",
    "- [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset of color training images, labeled over 10 categories.\n",
    "\n",
    "It has the classes:\n",
    "- airplane\n",
    "- automobile\n",
    "- bird\n",
    "- cat\n",
    "- deer\n",
    "- dog\n",
    "- frog\n",
    "- horse\n",
    "- ship\n",
    "- truck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ee2ul0ED1qoD"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c-pCdtFw1qoF"
   },
   "outputs": [],
   "source": [
    "# Uncomment the statements below if there are problems with TensorFlow on macOS\n",
    "# import os\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQgN2_6D1qoN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OohPiooS1qoQ"
   },
   "outputs": [],
   "source": [
    "# Uncomment the statement below to allow online monitoring with TensorBoard (need to be installed)\n",
    "# from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BAWeroBa1qoS"
   },
   "source": [
    "# Load data\n",
    "Use the **Keras**' load method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-Swb4TS1qoT"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('..\\Data\\cifar-10-batches-py\\data_batch_1', 'rb') as con:\n",
    "    data = pickle.load(con, encoding='bytes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bLdYg4g41qoX"
   },
   "source": [
    "## Check some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([b'batch_label', b'labels', b'data', b'filenames'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the data format:\n",
    "\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Swf_e6CR1qoY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3072)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data is 10,000 rows (each a picture)\n",
    "#Pictures are 32x32 = 1024 pixels, with 1024 each for red, blue and green values\n",
    "\n",
    "X = data[b'data']\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target values:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10,000 values for label of image\n",
    "\n",
    "y = np.array(data[b'labels'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There are 10 different labels for y (cat, dog, etc.):\n",
    "\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N-Jhbjf11qob"
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L9kdVXHd1qoc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One-hot encode the target variable y:\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y = to_categorical(y)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m2GU1EyK1qoe"
   },
   "source": [
    "# Create the model's architecture\n",
    "- **NOTE ALERT**: Take into account the volume of data and parameters. Time and processing escalate quite fast.\n",
    "- **NOTE ALERT**: It is likely this data will require more complex models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (7500, 32, 32, 3)\n",
      "y_train shape: (7500, 10)\n"
     ]
    }
   ],
   "source": [
    "#Reshape training data:\n",
    "\n",
    "X_train = X_train.reshape(-1,32,32,3)\n",
    "\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('y_train shape:',y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "82J0lM7d1qoe"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "#Stage 1\n",
    "model.add(keras.layers.Conv2D(filters = 32, kernel_size = (2,2), activation = 'relu', \n",
    "                              input_shape = (32,32,3),\n",
    "                              kernel_regularizer = keras.regularizers.l2(l2=0.01))) \n",
    "model.add(keras.layers.Dropout(0.4)) #Preventing overfitting\n",
    "\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters = 32, kernel_size = (2,2), activation = 'relu', \n",
    "                              \n",
    "                              kernel_regularizer = keras.regularizers.l2(l2=0.01))) \n",
    "model.add(keras.layers.Dropout(0.4))\n",
    "\n",
    "\n",
    "#Stage 2\n",
    "model.add(keras.layers.Conv2D(filters = 64, kernel_size = (2,2), activation = 'relu',                \n",
    "                              kernel_regularizer = keras.regularizers.l2(l2=0.01)))\n",
    "model.add(keras.layers.Dropout(0.4)) \n",
    "\n",
    "model.add(keras.layers.Conv2D(filters = 64, kernel_size = (2,2), activation = 'relu',            \n",
    "                              kernel_regularizer = keras.regularizers.l2(l2=0.01)))\n",
    "model.add(keras.layers.Dropout(0.4)) \n",
    "\n",
    "#Stage 3\n",
    "model.add(keras.layers.Conv2D(filters = 128, kernel_size = (2,2), activation = 'relu', \n",
    "                              kernel_regularizer = keras.regularizers.l2(l2=0.01)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters = 128, kernel_size = (2,2), activation = 'relu', \n",
    "                              kernel_regularizer = keras.regularizers.l2(l2=0.01)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters = 128, kernel_size = (2,2), activation = 'relu', \n",
    "                              kernel_regularizer = keras.regularizers.l2(l2=0.01)))\n",
    "\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "\n",
    "\n",
    "\n",
    "#Flatten outputs\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dropout(0.2)) \n",
    "#Last layer\n",
    "model.add(keras.layers.Dense(units = 10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dyq0xqGd1qoh"
   },
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'Adam',\n",
    "              loss = 'CategoricalCrossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_129 (Conv2D)          (None, 31, 31, 32)        416       \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_130 (Conv2D)          (None, 30, 30, 32)        4128      \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_131 (Conv2D)          (None, 29, 29, 64)        8256      \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_132 (Conv2D)          (None, 28, 28, 64)        16448     \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_133 (Conv2D)          (None, 27, 27, 128)       32896     \n",
      "_________________________________________________________________\n",
      "conv2d_134 (Conv2D)          (None, 26, 26, 128)       65664     \n",
      "_________________________________________________________________\n",
      "conv2d_135 (Conv2D)          (None, 25, 25, 128)       65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_90 (MaxPooling (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                184330    \n",
      "=================================================================\n",
      "Total params: 377,802\n",
      "Trainable params: 377,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zSv44CjG1qoh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.0545 - accuracy: 0.1035\n",
      "Epoch 2/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 5.8593 - accuracy: 0.1709\n",
      "Epoch 3/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 4.9985 - accuracy: 0.2385\n",
      "Epoch 4/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 4.3441 - accuracy: 0.2739\n",
      "Epoch 5/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 3.8103 - accuracy: 0.3008\n",
      "Epoch 6/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 3.3557 - accuracy: 0.3433\n",
      "Epoch 7/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 3.0192 - accuracy: 0.3576\n",
      "Epoch 8/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 2.7526 - accuracy: 0.3660\n",
      "Epoch 9/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 2.5341 - accuracy: 0.3885\n",
      "Epoch 10/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 2.3549 - accuracy: 0.3957\n",
      "Epoch 11/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 2.2066 - accuracy: 0.4091\n",
      "Epoch 12/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 2.0780 - accuracy: 0.4147\n",
      "Epoch 13/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.9899 - accuracy: 0.4320\n",
      "Epoch 14/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.9294 - accuracy: 0.4273\n",
      "Epoch 15/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.8514 - accuracy: 0.4477\n",
      "Epoch 16/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.7732 - accuracy: 0.4625\n",
      "Epoch 17/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.7371 - accuracy: 0.4575\n",
      "Epoch 18/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.6890 - accuracy: 0.4700\n",
      "Epoch 19/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.6711 - accuracy: 0.4736\n",
      "Epoch 20/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.6251 - accuracy: 0.4763\n",
      "Epoch 21/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.5994 - accuracy: 0.4945\n",
      "Epoch 22/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.5854 - accuracy: 0.4881\n",
      "Epoch 23/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.5622 - accuracy: 0.4991\n",
      "Epoch 24/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.5241 - accuracy: 0.5133\n",
      "Epoch 25/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.5183 - accuracy: 0.5109\n",
      "Epoch 26/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.4904 - accuracy: 0.5189\n",
      "Epoch 27/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.4807 - accuracy: 0.5216\n",
      "Epoch 28/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.4558 - accuracy: 0.5260\n",
      "Epoch 29/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.4468 - accuracy: 0.5333\n",
      "Epoch 30/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.4212 - accuracy: 0.5452\n",
      "Epoch 31/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.4275 - accuracy: 0.5461\n",
      "Epoch 32/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.3973 - accuracy: 0.5509\n",
      "Epoch 33/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.3871 - accuracy: 0.5517\n",
      "Epoch 34/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.3987 - accuracy: 0.5540\n",
      "Epoch 35/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.3580 - accuracy: 0.5657\n",
      "Epoch 36/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.3299 - accuracy: 0.5765\n",
      "Epoch 37/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.3415 - accuracy: 0.5743\n",
      "Epoch 38/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.3285 - accuracy: 0.5800\n",
      "Epoch 39/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.3285 - accuracy: 0.5807\n",
      "Epoch 40/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.3009 - accuracy: 0.5868\n",
      "Epoch 41/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.2935 - accuracy: 0.5911\n",
      "Epoch 42/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.2963 - accuracy: 0.5865\n",
      "Epoch 43/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.2775 - accuracy: 0.5979\n",
      "Epoch 44/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.2450 - accuracy: 0.6187\n",
      "Epoch 45/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.2412 - accuracy: 0.6103\n",
      "Epoch 46/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.2353 - accuracy: 0.6180\n",
      "Epoch 47/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.2200 - accuracy: 0.6188\n",
      "Epoch 48/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.2084 - accuracy: 0.6243\n",
      "Epoch 49/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.2328 - accuracy: 0.6233\n",
      "Epoch 50/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.1939 - accuracy: 0.6296\n",
      "Epoch 51/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.1868 - accuracy: 0.6337\n",
      "Epoch 52/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.1947 - accuracy: 0.6321\n",
      "Epoch 53/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.1876 - accuracy: 0.6328\n",
      "Epoch 54/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.1721 - accuracy: 0.6412\n",
      "Epoch 55/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.1644 - accuracy: 0.6393\n",
      "Epoch 56/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.1575 - accuracy: 0.6424\n",
      "Epoch 57/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.1527 - accuracy: 0.6433\n",
      "Epoch 58/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.1369 - accuracy: 0.6505\n",
      "Epoch 59/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.1431 - accuracy: 0.6448\n",
      "Epoch 60/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.1245 - accuracy: 0.6548\n",
      "Epoch 61/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.1292 - accuracy: 0.6564\n",
      "Epoch 62/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.1376 - accuracy: 0.6477\n",
      "Epoch 63/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.1216 - accuracy: 0.6644\n",
      "Epoch 64/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.1052 - accuracy: 0.6675\n",
      "Epoch 65/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.0842 - accuracy: 0.6661\n",
      "Epoch 66/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.1023 - accuracy: 0.6652\n",
      "Epoch 67/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.0861 - accuracy: 0.6751\n",
      "Epoch 68/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.1073 - accuracy: 0.6604\n",
      "Epoch 69/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.0873 - accuracy: 0.6684\n",
      "Epoch 70/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.0796 - accuracy: 0.6743\n",
      "Epoch 71/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.0655 - accuracy: 0.6743\n",
      "Epoch 72/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.0869 - accuracy: 0.6753\n",
      "Epoch 73/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.0694 - accuracy: 0.6793\n",
      "Epoch 74/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.0489 - accuracy: 0.6795\n",
      "Epoch 75/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.0559 - accuracy: 0.6829\n",
      "Epoch 76/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.0532 - accuracy: 0.6804\n",
      "Epoch 77/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.0582 - accuracy: 0.6827\n",
      "Epoch 78/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.0477 - accuracy: 0.6913\n",
      "Epoch 79/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.0330 - accuracy: 0.6936\n",
      "Epoch 80/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 3s 15ms/step - loss: 1.0262 - accuracy: 0.6923\n",
      "Epoch 81/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.0383 - accuracy: 0.6927\n",
      "Epoch 82/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.0453 - accuracy: 0.6852\n",
      "Epoch 83/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.0310 - accuracy: 0.6924\n",
      "Epoch 84/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.0415 - accuracy: 0.6879\n",
      "Epoch 85/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.0122 - accuracy: 0.6971\n",
      "Epoch 86/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.0371 - accuracy: 0.6848\n",
      "Epoch 87/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.0093 - accuracy: 0.6956\n",
      "Epoch 88/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.0083 - accuracy: 0.6957\n",
      "Epoch 89/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.0112 - accuracy: 0.6977\n",
      "Epoch 90/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.0143 - accuracy: 0.6959\n",
      "Epoch 91/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.0023 - accuracy: 0.7033\n",
      "Epoch 92/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9939 - accuracy: 0.7071\n",
      "Epoch 93/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 1.0106 - accuracy: 0.7052\n",
      "Epoch 94/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9966 - accuracy: 0.7087\n",
      "Epoch 95/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9965 - accuracy: 0.7027\n",
      "Epoch 96/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9845 - accuracy: 0.7029\n",
      "Epoch 97/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9960 - accuracy: 0.6956\n",
      "Epoch 98/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9909 - accuracy: 0.7001\n",
      "Epoch 99/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9862 - accuracy: 0.7111\n",
      "Epoch 100/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9750 - accuracy: 0.7123\n",
      "Epoch 101/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9969 - accuracy: 0.7055\n",
      "Epoch 102/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9811 - accuracy: 0.7068\n",
      "Epoch 103/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9629 - accuracy: 0.7121\n",
      "Epoch 104/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9852 - accuracy: 0.7087\n",
      "Epoch 105/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9752 - accuracy: 0.7123\n",
      "Epoch 106/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9811 - accuracy: 0.7096\n",
      "Epoch 107/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9565 - accuracy: 0.7191\n",
      "Epoch 108/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9529 - accuracy: 0.7221\n",
      "Epoch 109/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9775 - accuracy: 0.7112\n",
      "Epoch 110/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9707 - accuracy: 0.7061\n",
      "Epoch 111/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9605 - accuracy: 0.7140\n",
      "Epoch 112/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9523 - accuracy: 0.7231\n",
      "Epoch 113/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9573 - accuracy: 0.7207\n",
      "Epoch 114/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9597 - accuracy: 0.7105\n",
      "Epoch 115/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9489 - accuracy: 0.7208\n",
      "Epoch 116/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9400 - accuracy: 0.7228\n",
      "Epoch 117/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9631 - accuracy: 0.7183\n",
      "Epoch 118/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9416 - accuracy: 0.7203\n",
      "Epoch 119/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9368 - accuracy: 0.7264\n",
      "Epoch 120/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9297 - accuracy: 0.7289\n",
      "Epoch 121/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9254 - accuracy: 0.7339\n",
      "Epoch 122/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9359 - accuracy: 0.7227\n",
      "Epoch 123/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9412 - accuracy: 0.7171\n",
      "Epoch 124/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9414 - accuracy: 0.7197\n",
      "Epoch 125/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9234 - accuracy: 0.7283\n",
      "Epoch 126/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9245 - accuracy: 0.7276\n",
      "Epoch 127/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9366 - accuracy: 0.7228\n",
      "Epoch 128/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9210 - accuracy: 0.7348\n",
      "Epoch 129/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9447 - accuracy: 0.7236\n",
      "Epoch 130/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9202 - accuracy: 0.7311\n",
      "Epoch 131/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9233 - accuracy: 0.7275\n",
      "Epoch 132/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9145 - accuracy: 0.7365\n",
      "Epoch 133/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9155 - accuracy: 0.7320\n",
      "Epoch 134/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9191 - accuracy: 0.7345\n",
      "Epoch 135/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9156 - accuracy: 0.7296\n",
      "Epoch 136/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9330 - accuracy: 0.7220\n",
      "Epoch 137/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9241 - accuracy: 0.7292\n",
      "Epoch 138/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9053 - accuracy: 0.7315\n",
      "Epoch 139/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9205 - accuracy: 0.7261\n",
      "Epoch 140/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9166 - accuracy: 0.7289\n",
      "Epoch 141/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8909 - accuracy: 0.7389\n",
      "Epoch 142/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8911 - accuracy: 0.7323\n",
      "Epoch 143/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9006 - accuracy: 0.7332\n",
      "Epoch 144/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9082 - accuracy: 0.7327\n",
      "Epoch 145/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9082 - accuracy: 0.7352\n",
      "Epoch 146/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8956 - accuracy: 0.7452\n",
      "Epoch 147/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8800 - accuracy: 0.7431\n",
      "Epoch 148/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8931 - accuracy: 0.7384\n",
      "Epoch 149/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8961 - accuracy: 0.7396\n",
      "Epoch 150/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8914 - accuracy: 0.7420\n",
      "Epoch 151/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9022 - accuracy: 0.7376\n",
      "Epoch 152/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9075 - accuracy: 0.7343\n",
      "Epoch 153/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8995 - accuracy: 0.7356\n",
      "Epoch 154/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8760 - accuracy: 0.7471\n",
      "Epoch 155/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8821 - accuracy: 0.7387\n",
      "Epoch 156/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8945 - accuracy: 0.7405\n",
      "Epoch 157/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9124 - accuracy: 0.7335\n",
      "Epoch 158/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9032 - accuracy: 0.7331\n",
      "Epoch 159/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8917 - accuracy: 0.7401\n",
      "Epoch 160/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8858 - accuracy: 0.7401\n",
      "Epoch 161/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8987 - accuracy: 0.7345\n",
      "Epoch 162/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8723 - accuracy: 0.7441\n",
      "Epoch 163/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8759 - accuracy: 0.7483\n",
      "Epoch 164/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9011 - accuracy: 0.7299\n",
      "Epoch 165/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8913 - accuracy: 0.7407\n",
      "Epoch 166/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8848 - accuracy: 0.7400\n",
      "Epoch 167/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8821 - accuracy: 0.7463\n",
      "Epoch 168/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8941 - accuracy: 0.7379\n",
      "Epoch 169/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8932 - accuracy: 0.7408\n",
      "Epoch 170/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8711 - accuracy: 0.7492\n",
      "Epoch 171/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8661 - accuracy: 0.7488\n",
      "Epoch 172/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8922 - accuracy: 0.7397\n",
      "Epoch 173/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8623 - accuracy: 0.7504\n",
      "Epoch 174/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.9080 - accuracy: 0.7360\n",
      "Epoch 175/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8820 - accuracy: 0.7461\n",
      "Epoch 176/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8816 - accuracy: 0.7416\n",
      "Epoch 177/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8732 - accuracy: 0.7489\n",
      "Epoch 178/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8819 - accuracy: 0.7409\n",
      "Epoch 179/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8601 - accuracy: 0.7539\n",
      "Epoch 180/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8708 - accuracy: 0.7508\n",
      "Epoch 181/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8552 - accuracy: 0.7541\n",
      "Epoch 182/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8678 - accuracy: 0.7480\n",
      "Epoch 183/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8917 - accuracy: 0.7312\n",
      "Epoch 184/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8558 - accuracy: 0.7500\n",
      "Epoch 185/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8560 - accuracy: 0.7569\n",
      "Epoch 186/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8476 - accuracy: 0.7544\n",
      "Epoch 187/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8744 - accuracy: 0.7439\n",
      "Epoch 188/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8568 - accuracy: 0.7516\n",
      "Epoch 189/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8593 - accuracy: 0.7475\n",
      "Epoch 190/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8592 - accuracy: 0.7516\n",
      "Epoch 191/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8786 - accuracy: 0.7421\n",
      "Epoch 192/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8565 - accuracy: 0.7557\n",
      "Epoch 193/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8459 - accuracy: 0.7547\n",
      "Epoch 194/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8848 - accuracy: 0.7452\n",
      "Epoch 195/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8822 - accuracy: 0.7436\n",
      "Epoch 196/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8611 - accuracy: 0.7528\n",
      "Epoch 197/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8585 - accuracy: 0.7479\n",
      "Epoch 198/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8465 - accuracy: 0.7531\n",
      "Epoch 199/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8416 - accuracy: 0.7609\n",
      "Epoch 200/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8666 - accuracy: 0.7460\n",
      "Epoch 201/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8422 - accuracy: 0.7568\n",
      "Epoch 202/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8364 - accuracy: 0.7635\n",
      "Epoch 203/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8343 - accuracy: 0.7605\n",
      "Epoch 204/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8730 - accuracy: 0.7480\n",
      "Epoch 205/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8651 - accuracy: 0.7508\n",
      "Epoch 206/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8679 - accuracy: 0.7515\n",
      "Epoch 207/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8449 - accuracy: 0.7612\n",
      "Epoch 208/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8611 - accuracy: 0.7424\n",
      "Epoch 209/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8752 - accuracy: 0.7475\n",
      "Epoch 210/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8713 - accuracy: 0.7449\n",
      "Epoch 211/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8672 - accuracy: 0.7493\n",
      "Epoch 212/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8410 - accuracy: 0.7611\n",
      "Epoch 213/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8534 - accuracy: 0.7527\n",
      "Epoch 214/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8263 - accuracy: 0.7636\n",
      "Epoch 215/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8650 - accuracy: 0.7507\n",
      "Epoch 216/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8499 - accuracy: 0.7591\n",
      "Epoch 217/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8542 - accuracy: 0.7548\n",
      "Epoch 218/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8366 - accuracy: 0.7581\n",
      "Epoch 219/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8308 - accuracy: 0.7608\n",
      "Epoch 220/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8475 - accuracy: 0.7556\n",
      "Epoch 221/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8509 - accuracy: 0.7573\n",
      "Epoch 222/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8586 - accuracy: 0.7529\n",
      "Epoch 223/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8258 - accuracy: 0.7621\n",
      "Epoch 224/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8551 - accuracy: 0.7585\n",
      "Epoch 225/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8518 - accuracy: 0.7573\n",
      "Epoch 226/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8316 - accuracy: 0.7633\n",
      "Epoch 227/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8546 - accuracy: 0.7567\n",
      "Epoch 228/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8322 - accuracy: 0.7604\n",
      "Epoch 229/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8527 - accuracy: 0.7556\n",
      "Epoch 230/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8368 - accuracy: 0.7545\n",
      "Epoch 231/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8495 - accuracy: 0.7587\n",
      "Epoch 232/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8472 - accuracy: 0.7560\n",
      "Epoch 233/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8173 - accuracy: 0.7625\n",
      "Epoch 234/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8402 - accuracy: 0.7580\n",
      "Epoch 235/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8385 - accuracy: 0.7592\n",
      "Epoch 236/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8440 - accuracy: 0.7596\n",
      "Epoch 237/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8274 - accuracy: 0.7621\n",
      "Epoch 238/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8318 - accuracy: 0.7644\n",
      "Epoch 239/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8323 - accuracy: 0.7587\n",
      "Epoch 240/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8474 - accuracy: 0.7539\n",
      "Epoch 241/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8290 - accuracy: 0.7659\n",
      "Epoch 242/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8267 - accuracy: 0.7648\n",
      "Epoch 243/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8292 - accuracy: 0.7691\n",
      "Epoch 244/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8359 - accuracy: 0.7625\n",
      "Epoch 245/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8340 - accuracy: 0.7601\n",
      "Epoch 246/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8379 - accuracy: 0.7589\n",
      "Epoch 247/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8202 - accuracy: 0.7649\n",
      "Epoch 248/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8293 - accuracy: 0.7635\n",
      "Epoch 249/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8355 - accuracy: 0.7575\n",
      "Epoch 250/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8373 - accuracy: 0.7597\n",
      "Epoch 251/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8156 - accuracy: 0.7667\n",
      "Epoch 252/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8184 - accuracy: 0.7695 0s - loss: 0.807\n",
      "Epoch 253/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8199 - accuracy: 0.7665\n",
      "Epoch 254/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8219 - accuracy: 0.7649\n",
      "Epoch 255/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8058 - accuracy: 0.7691\n",
      "Epoch 256/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8130 - accuracy: 0.7704\n",
      "Epoch 257/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8162 - accuracy: 0.7652\n",
      "Epoch 258/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8164 - accuracy: 0.7697\n",
      "Epoch 259/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8039 - accuracy: 0.7732\n",
      "Epoch 260/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8206 - accuracy: 0.7655\n",
      "Epoch 261/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8273 - accuracy: 0.7596\n",
      "Epoch 262/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8328 - accuracy: 0.7613\n",
      "Epoch 263/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8195 - accuracy: 0.7627\n",
      "Epoch 264/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8223 - accuracy: 0.7708\n",
      "Epoch 265/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8317 - accuracy: 0.7589\n",
      "Epoch 266/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8287 - accuracy: 0.7625\n",
      "Epoch 267/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8117 - accuracy: 0.7688\n",
      "Epoch 268/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8554 - accuracy: 0.7581\n",
      "Epoch 269/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8234 - accuracy: 0.7677\n",
      "Epoch 270/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8144 - accuracy: 0.7724\n",
      "Epoch 271/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8326 - accuracy: 0.7603\n",
      "Epoch 272/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8079 - accuracy: 0.7713\n",
      "Epoch 273/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8123 - accuracy: 0.7671\n",
      "Epoch 274/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8151 - accuracy: 0.7664\n",
      "Epoch 275/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8027 - accuracy: 0.7769\n",
      "Epoch 276/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8179 - accuracy: 0.7681\n",
      "Epoch 277/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8358 - accuracy: 0.7579\n",
      "Epoch 278/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8076 - accuracy: 0.7709\n",
      "Epoch 279/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8163 - accuracy: 0.7657\n",
      "Epoch 280/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8188 - accuracy: 0.7685\n",
      "Epoch 281/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8192 - accuracy: 0.7732\n",
      "Epoch 282/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7959 - accuracy: 0.7724\n",
      "Epoch 283/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8020 - accuracy: 0.7716\n",
      "Epoch 284/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8206 - accuracy: 0.7641\n",
      "Epoch 285/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8219 - accuracy: 0.7652\n",
      "Epoch 286/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8170 - accuracy: 0.7657\n",
      "Epoch 287/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7963 - accuracy: 0.7777\n",
      "Epoch 288/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8237 - accuracy: 0.7639\n",
      "Epoch 289/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8134 - accuracy: 0.7677\n",
      "Epoch 290/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7998 - accuracy: 0.7737\n",
      "Epoch 291/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8214 - accuracy: 0.7620\n",
      "Epoch 292/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8168 - accuracy: 0.7689\n",
      "Epoch 293/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8089 - accuracy: 0.7663\n",
      "Epoch 294/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7933 - accuracy: 0.7751\n",
      "Epoch 295/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8134 - accuracy: 0.7708\n",
      "Epoch 296/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8037 - accuracy: 0.7761\n",
      "Epoch 297/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8040 - accuracy: 0.7704\n",
      "Epoch 298/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7743 - accuracy: 0.7833\n",
      "Epoch 299/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8189 - accuracy: 0.7612\n",
      "Epoch 300/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8181 - accuracy: 0.7653\n",
      "Epoch 301/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8013 - accuracy: 0.7773\n",
      "Epoch 302/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7994 - accuracy: 0.7803\n",
      "Epoch 303/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8326 - accuracy: 0.7625\n",
      "Epoch 304/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8192 - accuracy: 0.7696\n",
      "Epoch 305/400\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.8003 - accuracy: 0.7717\n",
      "Epoch 306/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8151 - accuracy: 0.7708\n",
      "Epoch 307/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7903 - accuracy: 0.7787\n",
      "Epoch 308/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7992 - accuracy: 0.7737\n",
      "Epoch 309/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7989 - accuracy: 0.7743\n",
      "Epoch 310/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8111 - accuracy: 0.7665\n",
      "Epoch 311/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8150 - accuracy: 0.7664\n",
      "Epoch 312/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8006 - accuracy: 0.7752\n",
      "Epoch 313/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8003 - accuracy: 0.7749\n",
      "Epoch 314/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7919 - accuracy: 0.7691\n",
      "Epoch 315/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8038 - accuracy: 0.7743\n",
      "Epoch 316/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7999 - accuracy: 0.7756\n",
      "Epoch 317/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8015 - accuracy: 0.7748\n",
      "Epoch 318/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7855 - accuracy: 0.7765\n",
      "Epoch 319/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8103 - accuracy: 0.7731\n",
      "Epoch 320/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7939 - accuracy: 0.7751\n",
      "Epoch 321/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8148 - accuracy: 0.7681\n",
      "Epoch 322/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7981 - accuracy: 0.7761\n",
      "Epoch 323/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7904 - accuracy: 0.7775\n",
      "Epoch 324/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7887 - accuracy: 0.7821\n",
      "Epoch 325/400\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.8261 - accuracy: 0.7677\n",
      "Epoch 326/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7968 - accuracy: 0.7791\n",
      "Epoch 327/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8008 - accuracy: 0.7777\n",
      "Epoch 328/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7959 - accuracy: 0.7801\n",
      "Epoch 329/400\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.8096 - accuracy: 0.7692\n",
      "Epoch 330/400\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.7832 - accuracy: 0.7845\n",
      "Epoch 331/400\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.7906 - accuracy: 0.7757\n",
      "Epoch 332/400\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.7959 - accuracy: 0.7735\n",
      "Epoch 333/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7819 - accuracy: 0.7816\n",
      "Epoch 334/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7904 - accuracy: 0.7797\n",
      "Epoch 335/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7977 - accuracy: 0.7728\n",
      "Epoch 336/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8075 - accuracy: 0.7705\n",
      "Epoch 337/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8141 - accuracy: 0.7693\n",
      "Epoch 338/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7907 - accuracy: 0.7739\n",
      "Epoch 339/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7946 - accuracy: 0.7784\n",
      "Epoch 340/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8006 - accuracy: 0.7740\n",
      "Epoch 341/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7979 - accuracy: 0.7731\n",
      "Epoch 342/400\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.7601 - accuracy: 0.7891\n",
      "Epoch 343/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7939 - accuracy: 0.7769\n",
      "Epoch 344/400\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.8023 - accuracy: 0.7740\n",
      "Epoch 345/400\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.7946 - accuracy: 0.7721\n",
      "Epoch 346/400\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.7933 - accuracy: 0.7737\n",
      "Epoch 347/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7931 - accuracy: 0.7796\n",
      "Epoch 348/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7821 - accuracy: 0.7853\n",
      "Epoch 349/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7933 - accuracy: 0.7741\n",
      "Epoch 350/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7992 - accuracy: 0.7727\n",
      "Epoch 351/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7998 - accuracy: 0.7749\n",
      "Epoch 352/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7796 - accuracy: 0.7804\n",
      "Epoch 353/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7952 - accuracy: 0.7813\n",
      "Epoch 354/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.8073 - accuracy: 0.7720\n",
      "Epoch 355/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7801 - accuracy: 0.7873\n",
      "Epoch 356/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7786 - accuracy: 0.7803\n",
      "Epoch 357/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7868 - accuracy: 0.7785\n",
      "Epoch 358/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7943 - accuracy: 0.7757\n",
      "Epoch 359/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7852 - accuracy: 0.7831\n",
      "Epoch 360/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7827 - accuracy: 0.7803\n",
      "Epoch 361/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7908 - accuracy: 0.7805\n",
      "Epoch 362/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7819 - accuracy: 0.7776\n",
      "Epoch 363/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7979 - accuracy: 0.7731\n",
      "Epoch 364/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7857 - accuracy: 0.7768\n",
      "Epoch 365/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7895 - accuracy: 0.7780\n",
      "Epoch 366/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7744 - accuracy: 0.7864\n",
      "Epoch 367/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7912 - accuracy: 0.7767\n",
      "Epoch 368/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7687 - accuracy: 0.7900\n",
      "Epoch 369/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7851 - accuracy: 0.7724\n",
      "Epoch 370/400\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.7954 - accuracy: 0.7697\n",
      "Epoch 371/400\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.7833 - accuracy: 0.7813\n",
      "Epoch 372/400\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.7908 - accuracy: 0.7801\n",
      "Epoch 373/400\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.7884 - accuracy: 0.7785\n",
      "Epoch 374/400\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.7892 - accuracy: 0.7775\n",
      "Epoch 375/400\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.8065 - accuracy: 0.7715\n",
      "Epoch 376/400\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.7656 - accuracy: 0.7893\n",
      "Epoch 377/400\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.7879 - accuracy: 0.7829\n",
      "Epoch 378/400\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.7711 - accuracy: 0.7883\n",
      "Epoch 379/400\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.7645 - accuracy: 0.7880\n",
      "Epoch 380/400\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.8038 - accuracy: 0.7704\n",
      "Epoch 381/400\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.7940 - accuracy: 0.7805\n",
      "Epoch 382/400\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.7789 - accuracy: 0.7816\n",
      "Epoch 383/400\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.7786 - accuracy: 0.7851\n",
      "Epoch 384/400\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.7769 - accuracy: 0.7839\n",
      "Epoch 385/400\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.7945 - accuracy: 0.7768\n",
      "Epoch 386/400\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.7719 - accuracy: 0.7855\n",
      "Epoch 387/400\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.7811 - accuracy: 0.7816\n",
      "Epoch 388/400\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.7830 - accuracy: 0.7767\n",
      "Epoch 389/400\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.7759 - accuracy: 0.7807\n",
      "Epoch 390/400\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.7849 - accuracy: 0.7769\n",
      "Epoch 391/400\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.7977 - accuracy: 0.7760\n",
      "Epoch 392/400\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.7585 - accuracy: 0.7917\n",
      "Epoch 393/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 3s 17ms/step - loss: 0.7841 - accuracy: 0.7817 0s - loss:\n",
      "Epoch 394/400\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.7910 - accuracy: 0.7885\n",
      "Epoch 395/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7786 - accuracy: 0.7788\n",
      "Epoch 396/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7771 - accuracy: 0.7835\n",
      "Epoch 397/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7933 - accuracy: 0.7743\n",
      "Epoch 398/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7934 - accuracy: 0.7787\n",
      "Epoch 399/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7795 - accuracy: 0.7847\n",
      "Epoch 400/400\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.7774 - accuracy: 0.7820\n",
      "Wall time: 19min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit(X_train,y_train, batch_size = 40, epochs = 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PCL-erlE1qol"
   },
   "source": [
    "### TensorBoard\n",
    "- TensorBoard is TensorFlow's visualisation toolkit. \n",
    "- If Tensorflow 2 and Jupyter is installed in the same environment, running the cell below will start TensorBoard within the notebook.\n",
    "- More information about how to set up TensorBoard can be found [here](https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_SC1MnqpABBQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 15464."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tQ_vBEpk1qom"
   },
   "source": [
    "# Create predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (2500, 32, 32, 3)\n",
      "y_test shape: (2500, 10)\n"
     ]
    }
   ],
   "source": [
    "#Reshape testing data:\n",
    "\n",
    "X_test = X_test.reshape(-1,32,32,3)\n",
    "\n",
    "print('X_test shape:',X_test.shape)\n",
    "print('y_test shape:',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EuVMau111qon"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500,)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict_classes(X_test)\n",
    "\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2lA8OW9e1qop"
   },
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 5ms/step - loss: 2.0797 - accuracy: 0.4892\n"
     ]
    }
   ],
   "source": [
    "#How come the accuracy is so low?\n",
    "\n",
    "results = model.evaluate(X_test,y_test, batch_size = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model keeps overfitting even with dropout and regularization, why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EI2omiec1qos"
   },
   "source": [
    "# Visualisation of cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_REk0bSz1qos"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "costs = history.history['loss']\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "\n",
    "plt.plot(costs)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cross-categorical Entropy')\n",
    "plt.title('Loss over epochs')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d1KBysuc1qou"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r2Rqvn1i1qou"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([268, 265, 231, 221, 224, 256, 217, 278, 302, 238], dtype=int64)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Counts of predicted classes:\n",
    "\n",
    "np.bincount(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Load models and weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open('model.json', 'w') as local_file:\n",
    "    local_file.write(model_json)\n",
    "\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "\n",
    "# load json and create model\n",
    "with open('model.json', 'r') as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "\n",
    "    \n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile loaded model to continue working with it\n",
    "\n",
    "loaded_model.compile() #etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RERADKgNFq9T"
   },
   "source": [
    " 2020 Institute of Data"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IOD_Lab-10_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
